{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06456f2b-ef4b-47bd-899d-130cd8c47b16",
   "metadata": {},
   "source": [
    "## Explore the finetuned LLaMa3 models : definitions, wordplay and solutions\n",
    "#### Also : Check validation set to see whether definition text leads to useful candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c6fc6f4-0134-40fb-9f3b-2acde63dc64c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip -q install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
    "#!pip -q install --no-deps \"xformers<0.0.26\" trl peft accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84206549-5ea7-4760-b41d-a54a4abb488c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'unsloth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01munsloth\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FastLanguageModel\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      5\u001b[0m HFCOMPANY\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHFCOMPANY\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcryptic-wordplay-formalizer\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'unsloth'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "HFCOMPANY=os.environ.get(\"HFCOMPANY\", \"cryptic-wordplay-formalizer\")\n",
    "\n",
    "max_seq_length = 512\n",
    "dtype = None\n",
    "load_in_4bit = True\n",
    "\"DONE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592d807d-794b-4938-a12a-e907a2731958",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# find ~/.cache | grep transformed_definition_finder_model_3_epochs\n",
    "#  ~/.cache/huggingface/hub/models--HFCOMPANY--transformed_definition_finder_model_3_epochs/blobs\n",
    "model, tokenizer = None, None\n",
    "def load_model_and_tokenizer(model_name, max_seq_len=max_seq_length):\n",
    "  global model, tokenizer\n",
    "  model, tokenizer = None, None\n",
    "\n",
    "  model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = model_name,\n",
    "    max_seq_length = max_seq_len,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    "  )\n",
    "  \n",
    "  # https://www.reddit.com/r/LocalLLaMA/comments/1ar7e4m/comment/kqndd8k/\n",
    "  #  .. https://github.com/unslothai/unsloth/blob/main/unsloth/models/loader.py#L187\n",
    "  \n",
    "  FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "  print(\"LOADED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6ba532",
   "metadata": {},
   "outputs": [],
   "source": [
    "from solver import llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33460ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAUSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea06288",
   "metadata": {},
   "source": [
    "## 'definition' bracketing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7128714-c1f5-4787-ab2d-ec55415ef326",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#load_model_and_tokenizer(f\"{HFCOMPANY}/transformed_definition_finder_model_3_epochs\")\n",
    "load_model_and_tokenizer(f\"./llama3-it_definition_guesser_1_epoch\", max_seq_len=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0ac2b8-1ada-4908-8ff8-6ffc12e21abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prompt_test = '''Cryptic clue definition annotation : add suitable brackets '{}' to:\n",
    "#clue: \"rotten, corrupt, independent politician ousting republican unable to function in congress\"\n",
    "#definition: '''\n",
    "\n",
    "prompts = llm.prompt_definition_guesser(llm.llama3_prompt, \n",
    "  \"rotten, corrupt, independent politician ousting republican unable to function in congress\"\n",
    ")\n",
    "\n",
    "inputs = tokenizer([prompts['prompt_test']], return_tensors=\"pt\").to(\"cuda\")\n",
    "outputs = model.generate(**inputs, max_new_tokens=64, use_cache=True, pad_token_id=tokenizer.eos_token_id)\n",
    "print( tokenizer.batch_decode(outputs)[0] )\n",
    "\"DONE\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2f17e4",
   "metadata": {},
   "source": [
    "## 'wordplay' creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c928b05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model_and_tokenizer(f\"{HFCOMPANY}/transformed_wordplay_guesser_model_3_epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb46f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_test = '''Cryptic clue wordplay generation:\n",
    "clue: \"socialist, a good sort, wouldn’t apply to oxbridge\"\n",
    "definition: socialist, a good sort, {wouldn’t apply to oxbridge}\n",
    "answer: REDBRICK\n",
    "wordplay: '''\n",
    "\n",
    "inputs = tokenizer([prompt_test], return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens=100, use_cache=True)\n",
    "print( tokenizer.batch_decode(outputs)[0] )\n",
    "\"DONE\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9e16f1",
   "metadata": {},
   "source": [
    "## Solutioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eec535f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEAD: load_model_and_tokenizer(f\"{HFCOMPANY}/cryptic_lora_test_model\")\n",
    "load_model_and_tokenizer(f\"{HFCOMPANY}/cryptic_wordplay_model_4_epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e3ff54",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "prompt_test = '''Cryptic clue wordplay to python : complete the following proof, adding wordplay to the docstring, and corresponding asserts to the function:\n",
    "def proof(answer=\"NANAS\", clue=\"Old relatives which featured on Hey Jude?\", pattern='5'):\n",
    "  \"\"\"\n",
    "  definition: {Old relatives} which featured on Hey Jude?\n",
    "  wordplay:'''\n",
    "\n",
    "inputs = tokenizer([prompt_test], return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens=512, use_cache=True)\n",
    "print( tokenizer.batch_decode(outputs)[0] )\n",
    "\"DONE\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98fec03-c3d8-424c-97db-8a6881a5f234",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Get Vector embeddings for Crossword Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80ff09b5-e328-4f4a-97d4-7d3d9304a005",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0433226a-3892-48ea-aa19-30d0983fbac9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, re\n",
    "import time, datetime, pytz\n",
    "\n",
    "tz = pytz.timezone('Asia/Singapore')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from solver.corpora import VectorEmbedder, CrosswordDictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "922e91b9-1c4d-45a8-9c18-7b4a89d664a8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ./cc.en.100.bin\n",
      "  .. took 7.25s\n",
      "Loading as_lower_case=True embeddings took 0.0267s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "304658"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0=time.time()\n",
    "embedder = None\n",
    "embedder = VectorEmbedder()  # May take a while...\n",
    "print(f\"  .. took {(time.time()-t0):.3}s\")  # 23secs on first load, 3.4 sec for second...\n",
    "\n",
    "crossword_dictionary = CrosswordDictionary(embedder)  # Embedding loading = 1.9s\n",
    "len(crossword_dictionary.wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c810a25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bienseance', 'bienseances']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# abbé : chacun : arri : bien- : teau : \n",
    "[ w for w in crossword_dictionary.wordlist if 'biens' in w ]\n",
    "# Hmm - not sure how these get entered into the grid..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ad267aa-fa33-4673-a0bc-aa7c6deb855b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((304658, 100), np.float32(0.99999994))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossword_dictionary.vec.shape, np.linalg.norm(crossword_dictionary.vec[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c595678-c5ef-40fd-97b5-99194a5ce54a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'phrase': 'offers', 'score': np.float32(0.72498935)},\n",
       " {'phrase': 'allows', 'score': np.float32(0.6161012)},\n",
       " {'phrase': 'avails', 'score': np.float32(0.5957378)},\n",
       " {'phrase': 'serves', 'score': np.float32(0.59341943)},\n",
       " {'phrase': 'ensure', 'score': np.float32(0.5613873)},\n",
       " {'phrase': 'brings', 'score': np.float32(0.55969435)},\n",
       " {'phrase': 'impart', 'score': np.float32(0.54872674)},\n",
       " {'phrase': 'boasts', 'score': np.float32(0.5413467)},\n",
       " {'phrase': 'onsite', 'score': np.float32(0.53032106)},\n",
       " {'phrase': 'unique', 'score': np.float32(0.5301597)},\n",
       " {'phrase': 'ushers', 'score': np.float32(0.52749133)},\n",
       " {'phrase': 'infuse', 'score': np.float32(0.52186507)},\n",
       " {'phrase': 'allots', 'score': np.float32(0.5174052)},\n",
       " {'phrase': 'warmth', 'score': np.float32(0.51728916)},\n",
       " {'phrase': 'direct', 'score': np.float32(0.5114685)},\n",
       " {'phrase': 'enable', 'score': np.float32(0.50896907)},\n",
       " {'phrase': 'exudes', 'score': np.float32(0.50860727)},\n",
       " {'phrase': 'blends', 'score': np.float32(0.50717443)},\n",
       " {'phrase': 'dining', 'score': np.float32(0.50200444)},\n",
       " {'phrase': 'extols', 'score': np.float32(0.4981169)},\n",
       " {'phrase': 'boosts', 'score': np.float32(0.49727488)},\n",
       " {'phrase': 'robust', 'score': np.float32(0.49720195)},\n",
       " {'phrase': 'savour', 'score': np.float32(0.4925838)},\n",
       " {'phrase': 'guests', 'score': np.float32(0.48902225)},\n",
       " {'phrase': 'evokes', 'score': np.float32(0.48769373)},\n",
       " {'phrase': 'awaits', 'score': np.float32(0.4842194)},\n",
       " {'phrase': 'imbues', 'score': np.float32(0.48384136)},\n",
       " {'phrase': 'lively', 'score': np.float32(0.48326927)},\n",
       " {'phrase': 'imbibe', 'score': np.float32(0.4823384)},\n",
       " {'phrase': 'bathes', 'score': np.float32(0.48105073)},\n",
       " {'phrase': 'enjoys', 'score': np.float32(0.48016605)},\n",
       " {'phrase': 'aromas', 'score': np.float32(0.47948587)},\n",
       " {'phrase': 'serene', 'score': np.float32(0.4793327)},\n",
       " {'phrase': 'guided', 'score': np.float32(0.47728235)},\n",
       " {'phrase': 'superb', 'score': np.float32(0.4762685)},\n",
       " {'phrase': 'ampler', 'score': np.float32(0.47285926)},\n",
       " {'phrase': 'enrich', 'score': np.float32(0.4707532)},\n",
       " {'phrase': 'equips', 'score': np.float32(0.46944857)},\n",
       " {'phrase': 'stands', 'score': np.float32(0.46729696)},\n",
       " {'phrase': 'convey', 'score': np.float32(0.46718636)},\n",
       " {'phrase': 'caters', 'score': np.float32(0.46573716)},\n",
       " {'phrase': 'assist', 'score': np.float32(0.46213937)},\n",
       " {'phrase': 'supply', 'score': np.float32(0.45989832)},\n",
       " {'phrase': 'coffee', 'score': np.float32(0.45837504)},\n",
       " {'phrase': 'access', 'score': np.float32(0.45803672)},\n",
       " {'phrase': 'excels', 'score': np.float32(0.4578964)},\n",
       " {'phrase': 'rinses', 'score': np.float32(0.45592797)},\n",
       " {'phrase': 'suites', 'score': np.float32(0.45564526)},\n",
       " {'phrase': 'filled', 'score': np.float32(0.45493484)},\n",
       " {'phrase': 'savors', 'score': np.float32(0.45462227)}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#crossword_dictionary.find_nearest_words('door', pattern='4,4', k=5)\n",
    "crossword_dictionary.find_nearest_words('provides refreshment', pattern='6', k=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9aa8c7a-2e74-4a20-a008-a8547482d60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float32(0.41820693), np.float32(0.660277))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_clue, test_def, test_gold = 'Cut up over politician on the French case'.lower(), 'case', 'example'\n",
    "test_clue_emb = embedder.get_normalised_phrase_vector(test_clue)\n",
    "test_def_emb  = embedder.get_normalised_phrase_vector(test_def)\n",
    "test_gold_emb = embedder.get_normalised_phrase_vector(test_gold)\n",
    "embedder.get_sim(test_clue_emb, test_gold_emb), embedder.get_sim(test_def_emb, test_gold_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27b3d4bb-1f60-4a78-a4bd-c08e4ad3d624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 {'phrase': 'example', 'score': np.float32(0.66027707)}\n"
     ]
    }
   ],
   "source": [
    "for idx, ex in enumerate( crossword_dictionary.find_nearest_words(test_def, pattern='7', k=10) ):\n",
    "  if ex['phrase']==test_gold:\n",
    "    print(idx, ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3bca2fa4-1418-42c5-8cc4-7d8841c742bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "631 {'phrase': 'example', 'score': np.float32(0.4182069)}\n"
     ]
    }
   ],
   "source": [
    "for idx, ex in enumerate( crossword_dictionary.find_nearest_words(test_clue, pattern='7', k=1000) ):\n",
    "  if ex['phrase']==test_gold:\n",
    "    print(idx, ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0e77dd71-a947-470b-8790-b04db97c0807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 631 {'phrase': 'example', 'score': np.float32(0.4182069)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['E', '_', 'A', '_', 'P', '_', '_'], 999)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mask_as_list, blank_char, idx_of_valid = list('__A__L_'), '_', 0\n",
    "mask_as_list, blank_char, idx_of_valid = list('E_A_P__'), '_', 0\n",
    "for idx, ex in enumerate( crossword_dictionary.find_nearest_words(test_clue, pattern='7', k=1000) ):\n",
    "  invalid_candidate, candidate = False, ex['phrase'].upper()\n",
    "  for c_idx, c in enumerate(mask_as_list):\n",
    "    if c==blank_char: continue # Skip the blank_char - we're only checking against the given letters\n",
    "    if c != candidate[c_idx]:\n",
    "      invalid_candidate=True\n",
    "      #print(f\"{c} failed at position {c_idx} for {candidate}\")\n",
    "      break\n",
    "  if invalid_candidate:continue\n",
    "    \n",
    "  if candidate==test_gold.upper():\n",
    "    print(idx_of_valid, idx, ex)\n",
    "  idx_of_valid+=1\n",
    "mask_as_list, idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f2156e3-f649-4023-b8f1-68a0a2030935",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Get the crossword answers dataset\n",
    "#from datasets import load_dataset\n",
    "#CrosswordQA_dataset = load_dataset('albertxu/CrosswordQA', cache_dir=\"./datasets/CrosswordQA/\")\n",
    "#print(CrosswordQA_dataset)\n",
    "#for item in CrosswordQA_dataset['train'].take(10):\n",
    "#  print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cc0a8b-4a99-4dfa-85c4-1d882be696e1",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "963a893d-7113-475d-9b66-b88e2818f618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading combined tsv took 15.4s\n"
     ]
    }
   ],
   "source": [
    "from solver.corpora import CrosswordQA\n",
    "crossword_qa = CrosswordQA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "137b9d18-a9af-4417-89bc-97504fa9e33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          {SWEARING} : carols about to tolerate bad language\n",
      "             {CABOT} : explorer or actor sebastian\n",
      "              {PAAR} : tv talk pioneer\n",
      "{LEADBALLOON,LEAD BALLOON} : utter failure figuratively\n",
      "{DONKEYS YEARS,AEON,AMONTHOFSUNDAYS,DONKEYSYEARS,ALONGTIME,A MONTH OF SUNDAYS,E ON,EON,ALONG TIME,ETERNITY,EONS,AEO,AEONS,EPOCH} : ages and ages\n",
      "{HYDEPARK,HYDE PARK} : denmark a hyperactive place with a platform for free speech\n",
      "              {MESS} : clean-up target\n",
      "          {NILL,NAY} : archaic negative\n",
      "            {SKIERS} : people slaloming\n",
      "         {BODEGUERO} : man who runs a wine-shop\n",
      "            {KAISER} : late resident of doorn\n",
      "               {EAI} : whats up in portuguese\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4493721"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for idx, (k,v_set) in enumerate(crossword_qa.combined.items()):\n",
    "  vs='{'+','.join(list(v_set))+'}'\n",
    "  print(f\"{vs:>20s} : {k}\")\n",
    "  if idx>10: break\n",
    "len(crossword_qa.combined)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a74f5bd-258c-430a-8a2a-093695730253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ARGUMNT',\n",
       " 'ATTACHE',\n",
       " 'BAG',\n",
       " 'BIN',\n",
       " 'CABINET',\n",
       " 'CRATE',\n",
       " 'ETUI',\n",
       " 'EVENT',\n",
       " 'EXAMPLE',\n",
       " 'FEDERAL',\n",
       " 'I NSTANCE',\n",
       " 'IN ANY',\n",
       " 'IN NO',\n",
       " 'INANY',\n",
       " 'INNO',\n",
       " 'INSTANCE',\n",
       " 'LAWSUIT',\n",
       " 'LN STANCE',\n",
       " 'LNSTANCE',\n",
       " 'NOMINATIVE',\n",
       " 'SCOPE OUT',\n",
       " 'SCOPEOUT',\n",
       " 'SHEATH',\n",
       " 'TEST',\n",
       " 'TWELVE BOTTLES OF WINE',\n",
       " 'TWELVEBOTTLESOFWINE',\n",
       " 'WORST'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#crossword_qa.combined['garment part']\n",
    "#crossword_qa.combined['flat bread']\n",
    "#crossword_qa.combined['tandoori bread']\n",
    "#crossword_qa.combined['sodium']  # ''\n",
    "#crossword_qa.combined['composer']\n",
    "#crossword_qa.combined['anger']\n",
    "crossword_qa.combined['case']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9c42ed-2322-4d1d-8fe7-a036850a51b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bdf21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAUSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d44ba0",
   "metadata": {},
   "source": [
    "## Load up the definitions model with support functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476cf6cb-6c72-47ec-9cf9-ebbbb9ec109b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model_name = f\"{HFCOMPANY}/transformed_definition_finder_model_3_epochs\"\n",
    "#model_name = f\"{HFCOMPANY}/transformed_definitions_wraptokens_model_3_epochs_19_05_24\"\n",
    "#model_name = f\"./llama3-it_definition_guesser_1_epoch\" # local\n",
    "#model_name = f\"./llama3-it_definition_guesser_3_epoch\" # local\n",
    "#model_name = f\"./llama3-it_definition_guesser_3_epoch_noex\" # local\n",
    "model_name = f\"./llama3-it_definition_guesser_4_epoch_noex\" # local - updated wordplay dataset '}{}{'\n",
    "\n",
    "load_model_and_tokenizer(model_name, max_seq_len=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd7d29b-dfae-41c3-895c-8b21f61b8373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_file_name(t, model_name, split='val'):  # stub='gemini'\n",
    "  pth=f\"./experiments/definitions/{model_name.replace('/', '_')}\"\n",
    "  os.makedirs(pth, exist_ok=True)\n",
    "  dt = time.strftime('%Y-%m-%d_%H-%M-%S', time.gmtime(t)) # Suitable for filename\n",
    "  return f'{pth}/{split}_{dt}.log'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa4531e-8512-4b06-8a65-c7c623d0cd6f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_definition_response(data_item, flog=None):\n",
    "  # Need to take off the pattern...\n",
    "  clue = data_item['clue']\n",
    "  pattern = data_item['enumeration'].replace('(', '').replace(')', '')\n",
    "  clue_updated = clue.replace( f\"({pattern})\", \"\").strip()\n",
    "  data_item['clue']=clue_updated\n",
    "  #print(f\"{clue=}, {pattern=}, {clue_updated=}\")\n",
    "  \n",
    "  prompts = llm.prompt_definition_guesser(llm.llama3_prompt, data_item['clue'])\n",
    "  prompt = prompts['prompt_test']\n",
    "  \n",
    "  inputs = tokenizer([prompt], return_tensors=\"pt\").to(\"cuda\")\n",
    "  prompt_length = inputs['input_ids'].shape[1]\n",
    "\n",
    "  outputs = model.generate(**inputs, max_new_tokens=64, use_cache=True, pad_token_id=tokenizer.eos_token_id)\n",
    "  # Return only new(ish) tokens : Need to back off a little... (since 'definition: ' is in prompt)\n",
    "  response_text =  tokenizer.batch_decode(outputs[:, prompt_length-10:])[0]  \n",
    "  #print(f\"response_text=\\n{response_text}\")\n",
    "\n",
    "  def eot_truncate(ans, eot):\n",
    "    if eot in ans:\n",
    "      pos = ans.index(eot)\n",
    "      ans = ans[:pos]\n",
    "    return ans\n",
    "  \n",
    "  ans, definition_str = 'DEFNOTFOUND', 'definition:'\n",
    "  for line in response_text.split('\\n'):\n",
    "    line = line.strip()\n",
    "    if line.startswith(definition_str):\n",
    "      ans=line[len(definition_str):].strip()\n",
    "      ans = eot_truncate(ans, '<|end_of_text|>')\n",
    "      ans = eot_truncate(ans, '<|eot_id|>')\n",
    "      ans=ans.strip()\n",
    "      break\n",
    "\n",
    "  if flog is not None:\n",
    "    flog.write('\\n---PROMPT---\\n')\n",
    "    flog.write(prompt)\n",
    "    flog.write('\\n---RESPONSE---\\n')\n",
    "    flog.write(response_text)\n",
    "    flog.write(f\"\\n---#RESULT#---:*:{data_item['idx_shuffled']}:*:{data_item['idx_orig']}:*:{ans}\\n\")\n",
    "  \n",
    "  return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f57dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAUSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d527d24-4fd1-406b-8172-735db27ea9f1",
   "metadata": {},
   "source": [
    "## Use the 'definition engine' to go through the Cryptonite validation set\n",
    "\n",
    "Store into a list, in val-set shuffled order (standardised):\n",
    "* The definition annotated version of the clue\n",
    "\n",
    "Also go through the list, in that order\n",
    "* Generate the nearest 20 words that match the pattern\n",
    "* Find (if possible) the actual answer in the list\n",
    "* Return a top-k score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15930de0-1d34-4cb0-b349-1e5fd988452f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26157"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from solver.dataset import load_cryptonite_dataset, get_shuffled_idx\n",
    "\n",
    "#data_train=load_cryptonite_dataset('train')\n",
    "data_val  =load_cryptonite_dataset('val')\n",
    "#data_test =load_cryptonite_dataset('test')\n",
    "shuffled_idx = get_shuffled_idx(data_val, seed=42)\n",
    "len(data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7709eb8d-6ea8-4fe9-8789-29667be014bd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "  idx=4\n",
    "  data_item = data_val[shuffled_idx[idx]]\n",
    "  #print(test_item)\n",
    "  print(f\"'{ get_definition_response(data_item) }' -> '{ data_item['answer'].upper() }' {data_item['enumeration']}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cd65f2-c26e-4a73-80d5-9a6329657954",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "t0=time.time()\n",
    "log_file = log_file_name(t0, model_name, split='val')\n",
    "flog = open(log_file, 'a')\n",
    "\n",
    "pos, cnt, samples = 0, 0, 100 # 0\n",
    "for idx in range(samples):\n",
    "  data_item = data_val[shuffled_idx[idx]]  \n",
    "  ans_model = get_definition_response(data_item, flog=flog)\n",
    "  ans_data  = data_item['answer'].upper()\n",
    "  print(f'Answer:\"{ans_data}\", Model.definition:\"{ans_model}\"')\n",
    "  #print(test_item)\n",
    "  #if ans_model==ans_data:\n",
    "  #  pos+=1\n",
    "  cnt+=1\n",
    "  \n",
    "  elapsed=(time.time()-t0)\n",
    "  remaining=elapsed/cnt*(samples-cnt)\n",
    "  eta_local = datetime.datetime.now(tz)+datetime.timedelta(seconds=remaining)\n",
    "  #print(f\"@{idx:4d} : {pos:4d}/{samples:4d} correct={100.*pos/cnt:5.2f}% ({elapsed/cnt:5.2f}s/iter ETA:{eta_local.strftime('%Y-%m-%d %H:%M:%S %Z')})\") # Remaining:{remaining:5.0f}s \n",
    "  print(f\"@{idx:4d}/{samples:4d} ({elapsed/cnt:5.2f}s/iter ETA:{eta_local.strftime('%Y-%m-%d %H:%M:%S %Z')})\") # Remaining:{remaining:5.0f}s \n",
    "  \n",
    "flog.close()\n",
    "print(f\"DONE : '{log_file}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a40d6a1-d586-42eb-a3db-756e7d3f0e08",
   "metadata": {
    "editable": true,
    "lines_to_next_cell": 0,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import solver.dataset \n",
    "# From the log-file :\n",
    "#   Find the FastText nearest neighbours that match the pattern (in data_val)\n",
    "#   compute the percentage correct\n",
    "def compute_score_from_logs(flog_arr):\n",
    "  overlaid = solver.dataset.read_log_results(flog_arr)  # CHECK THIS WORKS!\n",
    "  pos, cnt = 0, 0\n",
    "  pos_q, cnt_q = 0, 0\n",
    "  for idx, ans_model_arr in overlaid.items():\n",
    "    ans_model = ans_model_arr[0]\n",
    "    data_item = data_val[shuffled_idx[idx]]  # ONLY APPLICABLE TO 'val' SET\n",
    "\n",
    "    # Need to extract the definition...\n",
    "    definition=ans_model.replace('{', '').replace('}', '')  # Use the whole thing if nothing found\n",
    "    if '{' in ans_model and '}' in ans_model:\n",
    "      left = ans_model.index('{')\n",
    "      #right = ans_model.rindex('}')\n",
    "      right = ans_model.index('}', left)  # Pick first, if there are multiple sets of brackets\n",
    "      if 0<=left and left+1<right:\n",
    "        definition = ans_model[left+1:right]\n",
    "      \n",
    "    pattern_data  = data_item['enumeration']\n",
    "    match_arr = crossword_dictionary.find_nearest_words(definition, pattern=pattern_data, k=10)\n",
    "    matches = [ m['phrase'].upper() for m in match_arr ]\n",
    "    \n",
    "    answer_data  = data_item['answer']\n",
    "    correct = (answer_data.upper() in matches)\n",
    "    #print(f'@{idx: <4d} {\"matches!\" if correct else \"NO-MATCH\"} Model:\"{ans_model}\", Definition:\"{definition}\" GroundTruth:\"{answer_data.upper()}\" Candidates:[{\", \".join(matches)}]')\n",
    "    \n",
    "    print(f'@{idx: <4d} {\"matches!\" if correct else \"NO-MATCH\"} Model:\"{ans_model}\"')\n",
    "    print(f'        GroundTruth:\"{answer_data.upper()}\" present in dictionary:[{\", \".join(crossword_dictionary.find_substring_words(answer_data)[:10])}]')\n",
    "    print(f'        Definition:\"{definition}\" :  Candidates:[{\", \".join(matches)}]')\n",
    "    \n",
    "    if correct:\n",
    "      pos+=1\n",
    "    cnt+=1\n",
    "    if data_item['quick']:\n",
    "      if correct:\n",
    "        pos_q+=1\n",
    "      cnt_q+=1\n",
    "    \n",
    "  print(f\"Overall : {pos:4d}/{cnt:4d} correct={100.*pos/cnt:5.2f}%\")\n",
    "  if cnt_q>0:\n",
    "    print(f\"  Quick : {pos_q:4d}/{cnt_q:4d} correct={100.*pos_q/cnt_q:5.2f}%\")\n",
    "  print(f\"   Hard : {pos-pos_q:4d}/{cnt-cnt_q:4d} correct={100.*(pos-pos_q)/(cnt-cnt_q):5.2f}%\")\n",
    "\n",
    "compute_score_from_logs([\n",
    "  #f'./experiments/definitions/{HFCOMPANY}_transformed_definition_finder_model_3_epochs/test_2024-05-19_18-48-50.log',   # 20/100 : 4q+16h\n",
    "  #f'./experiments/definitions/{HFCOMPANY}_transformed_definitions_wraptokens_model_3_epochs_19_05_24/test_2024-05-20_05-30-47.log',  # 18/100 : 1q+17h\n",
    "  #f'./experiments/definitions/{HFCOMPANY}_transformed_definitions_wraptokens_model_3_epochs_19_05_24/test_2024-05-20_06-32-38.log',  # 21/100 : 2q+19h\n",
    "  log_file, # RUN ON VAL!\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e3bf95-6add-4400-b862-645eb19c8fc2",
   "metadata": {},
   "source": [
    "## Test definition finders on the Wordplay validation set\n",
    "#### Does the definition finder give a decent guess?\n",
    "\n",
    "* LLM definition finder compared to groundtruth (available in Wordplay)\n",
    "* TODO: Compared to answer->definition via datasets/CrosswordAnswers.tsv\n",
    "* TODO: Compared to answer->definition via FastText\n",
    "* TODO: Compared to answer->definition via WordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "649692ca-5641-4e53-8249-614cbbc2e75b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('DONE', [57, 99, 64, 186, 154], 282)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load up wordplay validation set\n",
    "from solver.dataset import get_wordplay_data_and_shuffle\n",
    "\n",
    "wordplay_val, shuffled_idx_wordplay_val = get_wordplay_data_and_shuffle('val')\n",
    "\"DONE\", shuffled_idx_wordplay_val[:5], len(shuffled_idx_wordplay_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4d12f1e-65bb-4ef2-a1a6-5762d2488e36",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_definition_response' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m data_item \u001b[38;5;241m=\u001b[39m wordplay_val[shuffled_idx_wordplay_val[idx]]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#print(test_item)\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[43mget_definition_response\u001b[49m(data_item)\u001b[38;5;250m \u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m =?= \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;250m \u001b[39mdata_item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;250m \u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for gold_def:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclue\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_definition_response' is not defined"
     ]
    }
   ],
   "source": [
    "# Get the definitions predicted for the Wordplay validation set\n",
    "if True:\n",
    "  idx=4\n",
    "  data_item = wordplay_val[shuffled_idx_wordplay_val[idx]]\n",
    "  #print(test_item)\n",
    "  print(f\"'{ get_definition_response(data_item) }' =?= '{ data_item['answer'].upper() }' for gold_def:{data_item['clue']}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593d758e-6de2-47a1-aa45-a015451dd0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0=time.time()\n",
    "log_file = log_file_name(t0, model_name, split='val')\n",
    "print(log_file)\n",
    "\n",
    "flog = open(log_file, 'a')\n",
    "\n",
    "pos, cnt, samples = 0, 0, len(shuffled_idx_wordplay_val) # 10 # \n",
    "for idx in range(samples):\n",
    "  data_item = wordplay_val[shuffled_idx_wordplay_val[idx]]  \n",
    "  def_model = get_definition_response(data_item, flog=flog)\n",
    "  ans_data  = data_item['answer'].upper()\n",
    "  def_data  = data_item['clue'] #.upper()\n",
    "  print(f'gold.answer:\"{ans_data}\":') #, gold.definition:\"{def_data}\", Model.definition:\"{def_model}\"')\n",
    "  print(f'   gold.definition: \"{def_data}\"')\n",
    "  print(f'   Model.definition:\"{def_model}\"')\n",
    "  #print(test_item)\n",
    "  if def_model.lower()==def_data.lower():\n",
    "    pos+=1\n",
    "  cnt+=1\n",
    "  \n",
    "  elapsed=(time.time()-t0)\n",
    "  remaining=elapsed/cnt*(samples-cnt)\n",
    "  eta_local = datetime.datetime.now(tz)+datetime.timedelta(seconds=remaining)\n",
    "  print(f\"@{idx:4d}/{samples:4d} {pos:3d}/{cnt:3d} ({elapsed/cnt:5.2f}s/iter ETA:{eta_local.strftime('%Y-%m-%d %H:%M:%S %Z')})\")\n",
    "  \n",
    "flog.close()\n",
    "print(f\"DONE : '{log_file}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c03cc61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall : 217.5/282.0 correct=77.13%\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from solver import prompts\n",
    "import solver.dataset \n",
    "\n",
    "def compute_definition_match_from_logs(flog_arr, guess_def_from_answer=False):\n",
    "  overlaid = solver.dataset.read_log_results(flog_arr)\n",
    "  \n",
    "  # Now that we have the 'final' ans in overlaid, let's score them vs wordplay_val\n",
    "  pos, cnt = 0, 0\n",
    "  pos_q, cnt_q = 0, 0\n",
    "  for idx, ans_model_arr in overlaid.items():\n",
    "    ans_model = ans_model_arr[0]  # Just first one is enough\n",
    "    #print(type(ans_model)); break\n",
    "    if type(ans_model)==dict:  # This is for the different format from def+wordplay output below\n",
    "      ans_model = ans_model['clue_with_def']\n",
    "      \n",
    "    data_item = wordplay_val[shuffled_idx_wordplay_val[idx]]\n",
    "    def_gold = data_item['clue']\n",
    "    \n",
    "    if guess_def_from_answer:\n",
    "      clues_with_defs = prompts.get_potential_definitions(data_item['answer'], def_gold, embedder)\n",
    "      clues_with_def_idx = random.randrange(len(clues_with_defs))\n",
    "      clue_with_def = clues_with_defs[ clues_with_def_idx ]\n",
    "      ans_model=clue_with_def\n",
    "    \n",
    "    correct=0.\n",
    "    if '{' in ans_model and '}' in ans_model:\n",
    "      left  = ans_model.index('{')\n",
    "      right = ans_model.index('}', left)  # Pick first, if there are multiple sets of brackets\n",
    "      if 0<=left and left+1<right:\n",
    "        #definition = ans_model[left+1:right]\n",
    "        if def_gold[left:left+1]=='{':\n",
    "          correct+=0.5\n",
    "        if def_gold[right:right+1]=='}':\n",
    "          correct+=0.5\n",
    "    #else:\n",
    "    #  print(f'No def in \"{ans_model}\"')\n",
    "    if False:\n",
    "      print(f'{correct:3.1f}')\n",
    "      print(f'  \"{def_gold}\"')\n",
    "      print(f'  \"{ans_model}\"')\n",
    "          \n",
    "    #if correct>0.6:\n",
    "    #  pos+=1.\n",
    "    pos+=correct\n",
    "    cnt+=1.\n",
    "  print(f\"Overall : {pos:4.1f}/{cnt:4.1f} correct={100.*pos/cnt:5.2f}%\")\n",
    "\n",
    "\n",
    "# Calculate the embedding-based definition finder score (uses gold answer)\n",
    "#compute_definition_match_from_logs([\n",
    "#  './experiments/definitions/reddragonai_transformed_definitions_wraptokens_model_3_epochs_19_05_24/val_2024-05-28_17-57-23.log',\n",
    "#], guess_def_from_answer=True)\n",
    "# Overall : 137.5/282.0 correct=48.76% \n",
    "\n",
    "compute_definition_match_from_logs([\n",
    "  # ICML orig submission (2024-05)\n",
    "  #'./experiments/definitions/reddragonai_transformed_definitions_wraptokens_model_3_epochs_19_05_24/val_2024-05-28_17-57-23.log',\n",
    "\n",
    "  # Score the def+wordplay file (i.e. LLM definition-finder using Gold Answer) (2024-06-26)\n",
    "  #'./experiments/wordplay/._llama3-it_def_and_wordplay_guesser_4_epoch_noex/val_2024-06-25_16-41-55.log',\n",
    "  \n",
    "  # Re-run after ICML acceptance (2024-06)\n",
    "  #'./experiments/definitions/reddragonai_transformed_definitions_wraptokens_model_3_epochs_19_05_24/val_2024-06-20_16-29-36.log',\n",
    "  # 1 epoch retrained definition_guesser\n",
    "  #'./experiments/definitions/._llama3-it_definition_guesser_1_epoch/val_2024-06-22_19-03-12.log',\n",
    "  # 3 epoch retrained definition_guesser\n",
    "  #'./experiments/definitions/._llama3-it_definition_guesser_3_epoch/val_2024-06-23_18-11-29.log',\n",
    "  #'./experiments/definitions/._llama3-it_definition_guesser_3_epoch/val_2024-06-23_19-31-25.log',  # Remove space after 'definition:' stub\n",
    "  # 3 epoch retrained definition_guesser - no example\n",
    "  #'./experiments/definitions/._llama3-it_definition_guesser_3_epoch_noex/val_2024-06-23_19-21-28.log',\n",
    "  # 3 epoch retrained definition_guesser - no example - declare 'expert'\n",
    "  #'./experiments/definitions/._llama3-it_definition_guesser_3_epoch_noex/val_2024-06-23_19-40-01.log',\n",
    "  # 3 epoch retrained definition_guesser - no example - declare 'expert' (no packing)\n",
    "  #'./experiments/definitions/._llama3-it_definition_guesser_3_epoch_noex/val_2024-06-24_17-16-57.log',\n",
    "  # 4 epoch retrained definition_guesser - no example - declare 'expert' (no packing, updated dataset)\n",
    "  './experiments/definitions/._llama3-it_definition_guesser_4_epoch_noex/val_2024-06-24_18-48-25.log'\n",
    "\n",
    "], guess_def_from_answer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78239f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sam LLM : completely correct       =40.07%   (def-from-answer-guesser = 28.01%)\n",
    "# Sam LLM : half-point for each side =51.95%   (def-from-answer-guesser = 48.76%)  # Updated\n",
    "\n",
    "# Updated prompting (2024-06-22) :: 1 epoch  of training : Overall : 85.5/282.0 correct=30.32%\n",
    "# Updated prompting (2024-06-24) :: 3 epochs of training : Overall : 114.0/282.0 correct=40.43%\n",
    "# Updated prompting (2024-06-24) :: 3 epochs of training : Overall : 128.0/282.0 correct=45.39% (remove space)\n",
    "# Updated prompting (2024-06-24) :: 3 epochs of training (no example) : Overall : 134.0/282.0 correct=47.52%\n",
    "# Updated prompting (2024-06-24) :: 3 epochs of training (no example, 'expert') : Overall : 137.0/282.0 correct=48.58%\n",
    "# Updated prompting (2024-06-24) :: 3 epochs of training (no example, 'expert') : Overall : 142.5/282.0 correct=50.53% (no packing)\n",
    "# Updated prompting (2024-06-24) :: 3 epochs of training (no example, 'expert') : Overall : 150.5/282.0 correct=53.37% (updated dataset)\n",
    "\n",
    "# Def+wordplay LLM (uses gold answer) : Overall : 217.5/282.0 correct=77.13%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4197c4f",
   "metadata": {},
   "source": [
    "## ICML orig : For Wordplay validation set : Create wordplay for 2 candidates\n",
    "For each item with a definition (in the previous log file)\n",
    "* create a 2nd candidate Answer from it (via embeddings)\n",
    "* create 5 wordplays for each candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8df6e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up wordplay model\n",
    "#model_name = f\"{HFCOMPANY}/transformed_wordplay_guesser_model_3_epochs\"\n",
    "model_name = f\"{HFCOMPANY}/transformed_wordplay_wraptokens_model_3_epochs_19_05_24\"\n",
    "load_model_and_tokenizer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b76ecd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_file_name_wordplay(t, model_name, split='val'):  # stub='gemini'\n",
    "  pth=f\"./experiments/wordplay/{model_name.replace('/', '_')}\"\n",
    "  os.makedirs(pth, exist_ok=True)\n",
    "  dt = time.strftime('%Y-%m-%d_%H-%M-%S', time.gmtime(t)) # Suitable for filename\n",
    "  return f'{pth}/{split}_{dt}.log'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42292742",
   "metadata": {},
   "outputs": [],
   "source": [
    "def XXXtransform_to_wordplay_guesser(example, answer_candidate=None):\n",
    "  \"\"\"\n",
    "  INPUT:\n",
    "clue: \"arrived with an artist, to get optical device (6)\"\n",
    "definition: arrived with an artist, to get {optical device}\n",
    "answer: CAMERA\n",
    "wordplay:\n",
    "\n",
    "  OUTPUT:\n",
    "CAME (arrived) + RA (artist, short form)\n",
    "\"\"\"\n",
    "\n",
    "  clue_with_def = example['clue'].lower().strip()\n",
    "  clue_no_def   = clue_with_def.replace('{','').replace('}','')\n",
    "  \n",
    "  example_answer = example['answer']\n",
    "  if answer_candidate is not None:\n",
    "    example_answer = answer_candidate\n",
    "    \n",
    "  system = f\"\"\"Cryptic clue wordplay generation : given the clue, definition annotations, and the answer, return suitable wordplay annotations\"\"\"\n",
    "  user = f'''\\n\n",
    "clue: \"{clue_no_def}\"\n",
    "definition: {clue_with_def}\n",
    "answer: {example_answer}'''.lstrip()\n",
    "  assistant = f'''wordplay: {example['wordplay'].strip()}\\n'''\n",
    "\n",
    "  prompt = f'''Cryptic clue wordplay generation:\n",
    "clue: \"{clue_no_def}\"\n",
    "definition: {clue_with_def}\n",
    "answer: {example_answer}\n",
    "wordplay: '''\n",
    "  answer = f'''{example['wordplay'].strip()}\\n'''\n",
    "\n",
    "  wraptokens_train = f'''<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n{system}<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "{user}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n{assistant}<|eot_id|><|end_of_text|>'''\n",
    "  wraptokens_test = f'''<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n{system}<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "{user}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\nwordplay: '''  # {assistant}<|eot_id|><|end_of_text|>\n",
    "\n",
    "  return {'prompt': prompt, 'answer': answer, # 'text_train': text_train, 'text_test': text_test,\n",
    "          'system': system, 'user': user, 'assistant':assistant, \n",
    "          'wraptokens_train': wraptokens_train, 'wraptokens_test': wraptokens_test}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468423ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import solver.dataset\n",
    "def get_wordplay_response(data_item, clue_with_def, answer_candidate, flog=None):\n",
    "  # Need to take off the pattern...\n",
    "  clue = data_item['clue']\n",
    "  pattern = data_item['enumeration'].replace('(', '').replace(')', '')\n",
    "  clue_updated = clue.replace( f\"({pattern})\", \"\").strip()\n",
    "  data_item['clue']=clue_updated\n",
    "  data_item['clue_with_def']=clue_with_def\n",
    "  \n",
    "  #example = transform_to_wordplay_guesser(data_item, answer_candidate)\n",
    "  #prompt = example['prompt_test']\n",
    "  #prompt = example['wraptokens_test']  #  if 'wraptokens' in model_name ...\n",
    "\n",
    "  NEED TO GET prompt HERE \n",
    "  \n",
    "  inputs = tokenizer([prompt], return_tensors=\"pt\").to(\"cuda\")\n",
    "  outputs = model.generate(**inputs, max_new_tokens=32, use_cache=True, pad_token_id=tokenizer.eos_token_id)\n",
    "  \n",
    "  response_text =  tokenizer.batch_decode(outputs)[0] \n",
    "  #print(f\"response_text=\\n{response_text}\")\n",
    "  \n",
    "  ans, wordplay_str = 'NOTFOUND', 'wordplay:'\n",
    "  for line in response_text.split('\\n'):\n",
    "    if line.startswith(wordplay_str):\n",
    "      ans=line[len(wordplay_str):].strip()\n",
    "      ans=ans.replace('<|end_of_text|>', '').strip()\n",
    "      break\n",
    "\n",
    "  if flog is not None:\n",
    "    flog.write('\\n---PROMPT---\\n')\n",
    "    flog.write(prompt)\n",
    "    flog.write('\\n---RESPONSE---\\n')\n",
    "    flog.write(response_text)\n",
    "    is_gold=(answer_candidate==data_item['answer'])\n",
    "    #flog.write(f\"\\n---#RESULT#---:*:{data_item['idx_shuffled']}:*:{data_item['idx_orig']}:*:\n",
    "    # {'0' if answer_candidate==data_item['answer'] else '1'}:*:{answer_candidate}:*:{ans}\\n\")\n",
    "    solver.dataset.write_log_result(flog, data_item['idx_shuffled'], data_item['idx_orig'], dict(\n",
    "      is_gold=is_gold,\n",
    "      candidate=0 if is_gold else 1,  # For now...\n",
    "      clue=clue_updated,\n",
    "      clue_with_def=clue_with_def, \n",
    "      pattern=pattern,\n",
    "      answer=answer_candidate,\n",
    "      wordplay=ans,\n",
    "    ))\n",
    "  \n",
    "  return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4aa831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the definitions predicted for the Wordplay validation set\n",
    "if True:\n",
    "  idx=4\n",
    "  data_item = wordplay_val[shuffled_idx_wordplay_val[idx]]\n",
    "  #print(test_item)\n",
    "  #print(f\"'{ get_wordplay_response(data_item) }' =?= '{ data_item['answer'].upper() }' for gold_def:{data_item['clue']}\" )\n",
    "  print(f\"model:'{ get_wordplay_response(data_item, data_item['clue'], data_item['answer']) }' =?= gold:'{ data_item['wordplay'] }'\" )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e815fd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go through the log file given, and get the definitions to attempt...\n",
    "definitions_found = solver.dataset.read_log_results([\n",
    "  #'./experiments/definitions/reddragonai_transformed_definitions_wraptokens_model_3_epochs_19_05_24/val_2024-05-28_17-57-23.log',\n",
    "  # Rerun of definition finder for ICML update\n",
    "  './experiments/definitions/reddragonai_transformed_definitions_wraptokens_model_3_epochs_19_05_24/val_2024-06-20_16-29-36.log',\n",
    "])\n",
    "len(definitions_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f13c629",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "t0=time.time()\n",
    "log_file = log_file_name_wordplay(t0, model_name, split='val')  # This is for our output\n",
    "print(log_file)\n",
    "flog = open(log_file, 'a')\n",
    "\n",
    "pos, cnt, samples = 0, 0, len(definitions_found) \n",
    "for idx, def_model_arr in definitions_found.items():\n",
    "  def_model = def_model_arr[0]\n",
    "  data_item = wordplay_val[shuffled_idx_wordplay_val[idx]]  \n",
    "  \n",
    "  ans_data  = data_item['answer'].upper()\n",
    "  for _ in range(5):\n",
    "    wordplay_model1 = get_wordplay_response(data_item, def_model, ans_data, flog=flog)\n",
    "\n",
    "  # Generate a new candidate from the def_model, close to the ans_data\n",
    "  definition = def_model.replace('{', '').replace('}', '')  # Use the whole thing if nothing found\n",
    "  if '{' in def_model and '}' in def_model:\n",
    "    left  = def_model.index('{')\n",
    "    right = def_model.index('}', left)  # Pick first, if there are multiple sets of brackets\n",
    "    if 0<=left and left+1<right:\n",
    "      definition = def_model[left+1:right]\n",
    "    \n",
    "  pattern_data  = data_item['enumeration']\n",
    "  match_arr = crossword_dictionary.find_nearest_words(definition, pattern=pattern_data, k=5)\n",
    "  matches = [ m['phrase'].upper() for m in match_arr ]\n",
    "  candidates = [m for m in matches if m!=ans_data]\n",
    "  answer_candidate = candidates[0] # Just one\n",
    "  \n",
    "  for _ in range(5):\n",
    "    wordplay_model2 = get_wordplay_response(data_item, def_model, answer_candidate, flog=flog)\n",
    "  \n",
    "  cnt+=1\n",
    "  \n",
    "  elapsed=(time.time()-t0)\n",
    "  remaining=elapsed/cnt*(samples-cnt)\n",
    "  eta_local = datetime.datetime.now(tz)+datetime.timedelta(seconds=remaining)\n",
    "  print(f\"@{idx:4d}/{samples:4d} ({elapsed/cnt:5.2f}s/iter ETA:{eta_local.strftime('%Y-%m-%d %H:%M:%S %Z')})\")\n",
    "\n",
    "  #break\n",
    "  \n",
    "flog.close()\n",
    "print(f\"DONE : '{log_file}'\")  # Takes ~20mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0aa23ae",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "wordplays_found = solver.dataset.read_log_results([\n",
    "  #'./experiments/wordplay/reddragonai_transformed_wordplay_wraptokens_model_3_epochs_19_05_24/val_2024-05-29_06-35-33.log',\n",
    "  #'./experiments/wordplay/reddragonai_transformed_wordplay_wraptokens_model_3_epochs_19_05_24/val_2024-05-29_06-50-10.log',\n",
    "  #'./experiments/wordplay/reddragonai_transformed_wordplay_wraptokens_model_3_epochs_19_05_24/val_2024-05-29_09-15-25.log', # has clue_with_def\n",
    "  # Run of definition finder for ICML cognitive\n",
    "  #'./experiments/wordplay/reddragonai_transformed_wordplay_wraptokens_model_3_epochs_19_05_24/val_2024-05-30_19-08-38.log', # 5 wordplays each\n",
    "  # Rerun of definition finder for ICML cognitive update\n",
    "  './experiments/wordplay/reddragonai_transformed_wordplay_wraptokens_model_3_epochs_19_05_24/val_2024-06-20_16-53-01.log', # 5 wordplays each\n",
    "])\n",
    "len(wordplays_found)  # Each entry has an array of result dicts in it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19154da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordplays_found[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e344fc",
   "metadata": {},
   "source": [
    "## For Wordplay validation set : Create definitions and wordplays for real answer + 1 alternative\n",
    "For each item in the wordplay validation set\n",
    "* 5 times for each\n",
    "  * Generate a definition and wordplay from genuine answer\n",
    "  * create a 2nd candidate Answer from it (via embeddings)\n",
    "  * Generate a definition and wordplay from alternative answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9da8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up definitions+wordplay model\n",
    "#model_name = f\"{HFCOMPANY}/transformed_wordplay_guesser_model_3_epochs\"\n",
    "#model_name = f\"{HFCOMPANY}/transformed_wordplay_wraptokens_model_3_epochs_19_05_24\"\n",
    "model_name = f\"./llama3-it_def_and_wordplay_guesser_4_epoch_noex\" # local\n",
    "\n",
    "load_model_and_tokenizer(model_name, max_seq_len=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e053a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_file_name_wordplay(t, model_name, split='val'):  # stub='gemini'\n",
    "  pth=f\"./experiments/wordplay/{model_name.replace('/', '_')}\"\n",
    "  os.makedirs(pth, exist_ok=True)\n",
    "  dt = time.strftime('%Y-%m-%d_%H-%M-%S', time.gmtime(t)) # Suitable for filename\n",
    "  return f'{pth}/{split}_{dt}.log'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5aabe74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up wordplay validation set\n",
    "from solver.dataset import get_wordplay_data_and_shuffle\n",
    "\n",
    "wordplay_val, shuffled_idx_wordplay_val = get_wordplay_data_and_shuffle('val')\n",
    "\"DONE\", shuffled_idx_wordplay_val[:5], len(shuffled_idx_wordplay_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37952c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import solver.dataset\n",
    "def get_def_and_wordplay_response(data_item, answer_candidate, flog=None):\n",
    "  # Need to take off the pattern...\n",
    "  clue = data_item['clue']\n",
    "  pattern = data_item['enumeration'].replace('(', '').replace(')', '')\n",
    "  clue_with_def = clue.replace( f\"({pattern})\", \"\").strip()\n",
    "  #data_item['clue']=clue_updated\n",
    "  clue_no_def   = clue_with_def.replace('{','').replace('}','').strip()\n",
    "\n",
    "  prompts = llm.prompt_def_and_wordplay_guesser(llm.llama3_prompt, clue_no_def, answer_candidate, '') # No definition or wordplay given\n",
    "  prompt = prompts['prompt_test']\n",
    "\n",
    "  inputs = tokenizer([prompt], return_tensors=\"pt\").to(\"cuda\")\n",
    "  prompt_length = inputs['input_ids'].shape[1]\n",
    "  \n",
    "  outputs = model.generate(**inputs, max_new_tokens=48, use_cache=True, pad_token_id=tokenizer.eos_token_id, \n",
    "                           temperature=0.5, do_sample=True)\n",
    "  # Return only new(ish) tokens : Need to back off a little... (since 'definition: ' is in prompt)\n",
    "  response_text =  tokenizer.batch_decode(outputs[:, prompt_length-10:])[0]  \n",
    "\n",
    "  def eot_truncate(ans, eot):\n",
    "    if eot in ans:\n",
    "      pos = ans.index(eot)\n",
    "      ans = ans[:pos]\n",
    "    return ans\n",
    "\n",
    "  fields, count_found, finished = { 'definition:':None, 'wordplay:':None, }, 0, False\n",
    "  for line in response_text.split('\\n'):\n",
    "    line = line.strip()\n",
    "    for k,v in fields.items():\n",
    "      if line.startswith(k) and v is None:\n",
    "        ans = line[len(k):].strip()\n",
    "        ans = eot_truncate(ans, '<|end_of_text|>')\n",
    "        ans = eot_truncate(ans, '<|eot_id|>')\n",
    "        fields[k]=ans.strip()\n",
    "        count_found+=1\n",
    "        if count_found==len(fields):\n",
    "          finished=True\n",
    "        break\n",
    "    if finished:\n",
    "      break\n",
    "\n",
    "  if flog is not None:\n",
    "    flog.write('\\n---PROMPT---\\n')\n",
    "    flog.write(prompt)\n",
    "    flog.write('\\n---RESPONSE---\\n')\n",
    "    flog.write(response_text)\n",
    "    is_gold=(answer_candidate==data_item['answer'])\n",
    "    #flog.write(f\"\\n---#RESULT#---:*:{data_item['idx_shuffled']}:*:{data_item['idx_orig']}:*:\n",
    "    # {'0' if answer_candidate==data_item['answer'] else '1'}:*:{answer_candidate}:*:{ans}\\n\")\n",
    "    solver.dataset.write_log_result(flog, data_item['idx_shuffled'], data_item['idx_orig'], dict(\n",
    "      is_gold=is_gold,\n",
    "      candidate=0 if is_gold else 1,  # For now...\n",
    "      clue=clue_no_def,\n",
    "      clue_with_def=fields['definition:'], \n",
    "      pattern=pattern,\n",
    "      answer=answer_candidate,\n",
    "      wordplay=fields['wordplay:'],\n",
    "    ))\n",
    "  \n",
    "  return fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232de46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for _ in range(20):  # Test sampling\n",
    "if True:  # Check 1 validation example\n",
    "  idx=14\n",
    "  data_item = wordplay_val[shuffled_idx_wordplay_val[idx]]\n",
    "  fields = get_def_and_wordplay_response(data_item, data_item['answer'])\n",
    "  print(f\"\"\"definition: model:'{ fields[\"definition:\"] }'\\n            gold: '{ data_item['clue'] }'\"\"\" )  \n",
    "  print(f\"\"\"  wordplay: model:'{ fields[\"wordplay:\"] }'  \\n            gold: '{ data_item['wordplay'] }'\"\"\" )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e660117",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "t0=time.time()\n",
    "log_file = log_file_name_wordplay(t0, model_name, split='val')  # This is for our output\n",
    "print(log_file)\n",
    "flog = open(log_file, 'a')\n",
    "\n",
    "pos, cnt, examples = 0, 0, len(shuffled_idx_wordplay_val)\n",
    "for idx in range(examples):\n",
    "  data_item = wordplay_val[shuffled_idx_wordplay_val[idx]]  \n",
    "  \n",
    "  ans_data  = data_item['answer'].upper()\n",
    "  for sample_idx in range(5):\n",
    "    # definition and wordplay get saved to log file...\n",
    "    fields_true_answer = get_def_and_wordplay_response(data_item, ans_data, flog=flog)\n",
    "    def_model = fields_true_answer['definition:']\n",
    "\n",
    "    # Generate a new candidate from the def_model, close to the ans_data\n",
    "    definition = def_model.replace('{', '').replace('}', '')  # Use the whole thing if nothing found\n",
    "    if '{' in def_model and '}' in def_model:\n",
    "      left  = def_model.index('{')\n",
    "      right = def_model.index('}', left)  # Pick first, if there are multiple sets of brackets\n",
    "      if 0<=left and left+1<right:\n",
    "        definition = def_model[left+1:right]\n",
    "    \n",
    "    pattern_data  = data_item['enumeration']\n",
    "    match_arr = crossword_dictionary.find_nearest_words(definition, pattern=pattern_data, k=5)\n",
    "    matches = [ m['phrase'].upper() for m in match_arr ]\n",
    "    candidates = [ m for m in matches if m!=ans_data and m.lower() not in definition.lower() ]\n",
    "    answer_candidate = candidates[0] # Just one\n",
    "  \n",
    "    # definition and wordplay get saved to log file...\n",
    "    fields_alternative_answer = get_def_and_wordplay_response(data_item, answer_candidate, flog=flog)\n",
    "  cnt+=1\n",
    "  \n",
    "  elapsed=(time.time()-t0)\n",
    "  remaining=elapsed/cnt*(examples-cnt)\n",
    "  eta_local = datetime.datetime.now(tz)+datetime.timedelta(seconds=remaining)\n",
    "  print(f\"@{idx:4d}/{examples:4d} ({elapsed/cnt:5.2f}s/iter ETA:{eta_local.strftime('%Y-%m-%d %H:%M:%S %Z')})\")\n",
    "  #break\n",
    "  \n",
    "flog.close()\n",
    "print(f\"DONE : '{log_file}'\")  # Takes ~1h20m for 282 examples in val (only need 100, though...)\n",
    "# ./experiments/wordplay/._llama3-it_def_and_wordplay_guesser_4_epoch_noex/val_2024-06-25_16-41-55.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c34a939",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "cache-notebooks//ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
