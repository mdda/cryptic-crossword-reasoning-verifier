{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36688951-d8da-4b83-bf77-a36751f0dbfe",
   "metadata": {},
   "source": [
    "## Creates a list of candidates for each Cryptonite train set entry\n",
    "#### Method validated using the validation set\n",
    "\n",
    "Idea here is to train a clue->answer model ...\n",
    "* with additional 'candidates' listed\n",
    "* so that model can learn to make suggestions\n",
    "* and pick the best answer from its list of suggestions\n",
    "\n",
    "Net result :: Didn't seem to help..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c7517f4-89ef-490f-85fb-d21b8837b264",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json, re\n",
    "import random\n",
    "import time, datetime, pytz\n",
    "\n",
    "tz = pytz.timezone('Asia/Singapore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "063d5254-9dde-4f7f-8cb3-554e11ff147a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c337f3ce-d626-4f92-92b7-840fc1828e41",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(470804, 26156, 26157)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from solver.cryptonite import load_cryptonite_dataset, get_shuffled_idx\n",
    "\n",
    "data_train =load_cryptonite_dataset('train')\n",
    "shuffled_idx_train = get_shuffled_idx(data_train, seed=42)\n",
    "\n",
    "data_val =load_cryptonite_dataset('val')\n",
    "shuffled_idx_val = get_shuffled_idx(data_val, seed=42)\n",
    "# use enumeration and answer\n",
    "\n",
    "data_test=load_cryptonite_dataset('test')\n",
    "shuffled_idx_test = get_shuffled_idx(data_test, seed=42)\n",
    "# use enumeration only\n",
    "\n",
    "len(data_train), len(data_val), len(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "380d60fd-9a96-42ec-9654-674121ea68bb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validation_set_hit_rate(arr, debug=False):\n",
    "  cnt,pos_model,pos_at_1,pos_max = 0,0,0,0\n",
    "  for item in arr:\n",
    "    idx_shuffled=item['idx_shuffled']\n",
    "    candidates = item['candidates']\n",
    "    \n",
    "    answer_val = data_val[idx_shuffled]['answer'] # Only calculates for the validation set!\n",
    "    if debug:\n",
    "      print(f\"({item['pattern']: >5s}) : GOLD='{answer_val}', model : {item['ans_model']} -> {candidates}\")\n",
    "    found=False\n",
    "    for ans in candidates:\n",
    "      if ans.upper()==answer_val.upper():\n",
    "        found=True\n",
    "    if found: \n",
    "      pos_max+=1\n",
    "    if candidates[0].upper()==answer_val.upper():\n",
    "      pos_at_1+=1\n",
    "    if item['ans_model'].upper()==answer_val.upper():\n",
    "      pos_model+=1\n",
    "    cnt+=1\n",
    "  print(f\"acc_model={pos_model/cnt*100.:.2f}%, acc@1={pos_at_1/cnt*100.:.2f}%, limit over candidates={pos_max/cnt*100.:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "527cac7e-6cb3-4429-9298-653f5abeb643",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_candidates_from_log(flog_arr, data_set, shuffled_idx):\n",
    "  overlaid = dict()\n",
    "  for flog in flog_arr:\n",
    "    with open(flog, 'r') as fin:\n",
    "      for line in fin.readlines():\n",
    "        if not '#RESULT#' in line: \n",
    "          continue\n",
    "        _,idx_shuffled, idx_orig, ans = line.split(':*:')\n",
    "        idx_shuffled=int(idx_shuffled)\n",
    "        overlaid[idx_shuffled]=ans.upper().strip()\n",
    "  # Now that we have the 'final' ans in overlaid, let's generate candidates for them\n",
    "  arr=[]\n",
    "  for idx, ans_model in overlaid.items():\n",
    "    # Have the answer from the model here...\n",
    "    idx_shuffled = shuffled_idx[idx]\n",
    "    item = data_set[idx_shuffled]  \n",
    "    pattern=item['enumeration'].replace('(', '').replace(')', '')\n",
    "    # This should be enough to generate extra variations\n",
    "    arr.append(dict(\n",
    "      idx=idx, idx_shuffled=idx_shuffled, clue=item['clue'], pattern=pattern, ans_model=ans_model,\n",
    "    ))\n",
    "  return arr\n",
    "def add_identity_candidates(arr):\n",
    "  for a in arr:\n",
    "    a['candidates'] = [a['ans_model'],]\n",
    "  return arr # modified in place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "194ab66a-6f82-42c0-8bb1-8ed4eb4d5088",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_model=18.80%, acc@1=18.80%, limit over candidates=18.80%\n"
     ]
    }
   ],
   "source": [
    "val_data = make_candidates_from_log([\n",
    "  './experiments/zero-shot/llama3_cryptonite_1_epoch/2024-05-21_08-49-41.log', \n",
    "], data_val, shuffled_idx_val)\n",
    "\n",
    "validation_set_hit_rate( add_identity_candidates(val_data) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ed185404-2580-4bb4-906a-7a93c7fe2d85",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from solver.corpora import VectorEmbedder, CrosswordDictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cd480ba3-9642-43fb-8d4a-f2efda2d9787",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ./cc.en.100.bin\n",
      "  .. took 3.49s\n",
      "Loading as_lower_case=True embeddings took 0.073s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "250353"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0=time.time()\n",
    "embedder = None\n",
    "embedder = VectorEmbedder()  # May take a while...\n",
    "print(f\"  .. took {(time.time()-t0):.3}s\")  # 23secs on first load, 3.4 sec for second...\n",
    "\n",
    "crossword_dictionary = CrosswordDictionary(embedder)  # Embedding loading = 1.9s\n",
    "len(crossword_dictionary.wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "53732355-317b-4e6f-b944-3a2506cb5c48",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#crossword_dictionary.find_nearest_words('door', pattern='4,4', k=5)\n",
    "#crossword_dictionary.find_nearest_words('on average', pattern='2,7', k=5)  # HUH - not in the dictionary!\n",
    "#crossword_dictionary.find_nearest_words('TOUCH AND GO', pattern='5,3,2', k=5)  # HUH - not in the dictionary!\n",
    "#crossword_dictionary.find_nearest_words('bury the hatchet', pattern='4,3,7', k=5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5a8fc8ae-b0d5-4d5e-9e57-87d30b778bf4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_model=18.80%, acc@1=21.10%, limit over candidates=22.30%\n",
      "  .. took 34.4s\n"
     ]
    }
   ],
   "source": [
    "from solver import pattern_to_re\n",
    "def add_embedding_nearest_candidates(arr):\n",
    "  k=2 # top-k matches\n",
    "  for a in arr:\n",
    "    ans_model, pattern = a['ans_model'], a['pattern']\n",
    "    match_arr = crossword_dictionary.find_nearest_words(ans_model, pattern=pattern, k=k)\n",
    "    matches = [ m['phrase'].upper() for m in match_arr if m['phrase'].upper()!=ans_model ]  # Take out ans_model\n",
    "    pattern_re = pattern_to_re(pattern)\n",
    "    if re.match(pattern_re, ans_model): # If the answer fits the pattern : add it \n",
    "      matches.insert(0, ans_model)\n",
    "      #print(f\"Added {ans_model}\")\n",
    "    a['candidates'] = matches[:k]  # Just first k\n",
    "    #print(f\"({a['pattern']: >5s}) : {a['ans_model']} -> {matches}\")\n",
    "  return arr # modified in place  \n",
    "\n",
    "t0=time.time()\n",
    "validation_set_hit_rate( add_embedding_nearest_candidates(val_data), debug=False )\n",
    "print(f\"  .. took {(time.time()-t0):.3}s\")  # \n",
    "# k=2 : acc_model=18.80%, acc@1=21.10%, limit over candidates=22.30%\n",
    "# k=3 : acc_model=18.80%, acc@1=21.10%, limit over candidates=22.70%\n",
    "# k=5 : acc_model=18.80%, acc@1=21.10%, limit over candidates=24.00% # Seems like nearest embedding doesn't help much...\n",
    "# .. 30-40 secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bda299cd-5545-47cd-900f-d192becf7ad5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_model=18.80%, acc@1=19.50%, limit over candidates=21.10%\n",
      "  .. took 37.0s\n"
     ]
    }
   ],
   "source": [
    "from solver import prompts\n",
    "\n",
    "def add_embedding_nearest_from_definition_candidates(arr):\n",
    "  k=2 # top-k matches\n",
    "  for a in arr:\n",
    "    ans_model, pattern, clue = a['ans_model'], a['pattern'], a['clue']\n",
    "    # Using the ans_model(!) find the definition within the clue,\n",
    "    #  Then find the matches closest to the definition words...\n",
    "    defs = prompts.get_potential_definitions(ans_model.upper(), clue, embedder)\n",
    "    #print(defs)\n",
    "    def_best = defs[0]  # This is the clue with some brackets in\n",
    "\n",
    "    definition = def_best.replace('{', '').replace('}', '')  # Use the whole thing if nothing found\n",
    "    left = def_best.index('{')\n",
    "    #right = def_best.rindex('}')\n",
    "    right = def_best.index('}', left)  # Pick first, if there are multiple sets of brackets\n",
    "    if 0<=left and left+1<right:\n",
    "      definition = def_best[left+1:right].replace(',', '').replace('?', '').replace('!', '')\n",
    "      \n",
    "    match_arr = crossword_dictionary.find_nearest_words(definition, pattern=pattern, k=k)\n",
    "    matches = [ m['phrase'].upper() for m in match_arr if m['phrase'].upper()!=ans_model ]  # Take out ans_model\n",
    "    pattern_re = pattern_to_re(pattern)\n",
    "    if re.match(pattern_re, ans_model): # If the answer fits the pattern : add it \n",
    "      matches.insert(0, ans_model)\n",
    "      #print(f\"Added {ans_model}\")\n",
    "    a['candidates'] = matches[:k]  # Just first k\n",
    "    #print(f\"({a['pattern']: >5s}) : definition='{definition}' {a['ans_model']} -> {matches}\")\n",
    "  return arr # modified in place  \n",
    "\n",
    "t0=time.time()\n",
    "validation_set_hit_rate( add_embedding_nearest_from_definition_candidates(val_data), debug=False )    # [:100]\n",
    "print(f\"  .. took {(time.time()-t0):.3}s\")  # \n",
    "# k=2 : acc_model=18.80%, acc@1=19.50%, limit over candidates=21.10%\n",
    "# k=3 : acc_model=18.80%, acc@1=19.50%, limit over candidates=22.30%\n",
    "# .. 35-45 secs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d70203-9959-4525-b0a2-9c0d67b90ee3",
   "metadata": {},
   "source": [
    "## Now assemble addional candidates for Cryptonite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "eed5ffea-e511-44e4-95e9-b02f8bac81a4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'publisher': 'Times',\n",
       "  'date': 971654400000,\n",
       "  'author': '',\n",
       "  'number': 6,\n",
       "  'orientation': 'across',\n",
       "  'clue': 'make progress socially in stated region (5)',\n",
       "  'answer': 'climb',\n",
       "  'enumeration': '(5)',\n",
       "  'quick': False,\n",
       "  'sub_publisher': 'The Times',\n",
       "  'idx_orig': 0,\n",
       "  'idx_shuffled': 53014,\n",
       "  'candidates': 'climb,bring,their,would,might'}]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_embedding_nearest_from_definition_candidates_for_dataset(arr):\n",
    "  k=5 # top-k matches\n",
    "  for a in arr:\n",
    "    answer, pattern, clue = a['answer'], a['enumeration'], a['clue']\n",
    "    # Using the answer to find the definition within the clue,\n",
    "    #  Then find the matches closest to the definition words...\n",
    "    defs = prompts.get_potential_definitions(answer.upper(), clue, embedder)\n",
    "    def_best = defs[0]  # This is the clue with some brackets in\n",
    "\n",
    "    definition = def_best.replace('{', '').replace('}', '')  # Use the whole thing if nothing found\n",
    "    left = def_best.index('{')\n",
    "    #right = def_best.rindex('}')\n",
    "    right = def_best.index('}', left)  # Pick first, if there are multiple sets of brackets\n",
    "    if 0<=left and left+1<right:\n",
    "      definition = def_best[left+1:right].replace(',', '').replace('?', '').replace('!', '')\n",
    "      \n",
    "    match_arr = crossword_dictionary.find_nearest_words(definition, pattern=pattern, k=k)\n",
    "    matches = [ m['phrase'].lower() for m in match_arr if m['phrase'].lower()!=answer ]  # Take out answer\n",
    "    matches = matches[:k-1] # shorten to k-1 entries \n",
    "    matches.append(answer)\n",
    "    random.shuffle(matches)\n",
    "    #print(f'{k=} {len(matches)=} {matches}')\n",
    "    a['candidates'] = ','.join(matches)\n",
    "    #print(f\"({a['pattern']: >5s}) : definition='{definition}' {answer} -> {matches}\")\n",
    "  return arr # modified in place  \n",
    "add_embedding_nearest_from_definition_candidates_for_dataset([data_train[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "5ffb26a2-7b84-4df4-95e3-4602dd9e1a79",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote './datasets/cryptonite_candidates/000000.jsonl' : 1000 in 34.86sec\n",
      "Wrote './datasets/cryptonite_candidates/001000.jsonl' : 1000 in 34.22sec\n",
      "Wrote './datasets/cryptonite_candidates/002000.jsonl' : 1000 in 35.21sec\n",
      "Wrote './datasets/cryptonite_candidates/003000.jsonl' : 1000 in 34.72sec\n",
      "Wrote './datasets/cryptonite_candidates/004000.jsonl' : 1000 in 34.57sec\n",
      "Wrote './datasets/cryptonite_candidates/005000.jsonl' : 1000 in 34.56sec\n",
      "Wrote './datasets/cryptonite_candidates/006000.jsonl' : 1000 in 34.22sec\n",
      "Wrote './datasets/cryptonite_candidates/007000.jsonl' : 1000 in 34.33sec\n",
      "Wrote './datasets/cryptonite_candidates/008000.jsonl' : 1000 in 34.82sec\n",
      "Wrote './datasets/cryptonite_candidates/009000.jsonl' : 1000 in 35.00sec\n",
      "Wrote './datasets/cryptonite_candidates/010000.jsonl' : 1000 in 34.47sec\n",
      "Wrote './datasets/cryptonite_candidates/011000.jsonl' : 1000 in 34.87sec\n",
      "Wrote './datasets/cryptonite_candidates/012000.jsonl' : 1000 in 34.55sec\n",
      "Wrote './datasets/cryptonite_candidates/013000.jsonl' : 1000 in 35.25sec\n",
      "Wrote './datasets/cryptonite_candidates/014000.jsonl' : 1000 in 35.55sec\n",
      "Wrote './datasets/cryptonite_candidates/015000.jsonl' : 1000 in 34.28sec\n",
      "Wrote './datasets/cryptonite_candidates/016000.jsonl' : 1000 in 34.84sec\n",
      "Wrote './datasets/cryptonite_candidates/017000.jsonl' : 1000 in 34.84sec\n",
      "Wrote './datasets/cryptonite_candidates/018000.jsonl' : 1000 in 34.74sec\n",
      "Wrote './datasets/cryptonite_candidates/019000.jsonl' : 1000 in 34.21sec\n",
      "Wrote './datasets/cryptonite_candidates/020000.jsonl' : 1000 in 34.76sec\n",
      "Wrote './datasets/cryptonite_candidates/021000.jsonl' : 1000 in 34.59sec\n",
      "Wrote './datasets/cryptonite_candidates/022000.jsonl' : 1000 in 34.35sec\n",
      "Wrote './datasets/cryptonite_candidates/023000.jsonl' : 1000 in 35.29sec\n",
      "Wrote './datasets/cryptonite_candidates/024000.jsonl' : 1000 in 35.37sec\n",
      "Wrote './datasets/cryptonite_candidates/025000.jsonl' : 1000 in 34.34sec\n",
      "Wrote './datasets/cryptonite_candidates/026000.jsonl' : 1000 in 38.56sec\n",
      "Wrote './datasets/cryptonite_candidates/027000.jsonl' : 1000 in 37.04sec\n",
      "Wrote './datasets/cryptonite_candidates/028000.jsonl' : 1000 in 35.38sec\n",
      "Wrote './datasets/cryptonite_candidates/029000.jsonl' : 1000 in 34.97sec\n",
      "Wrote './datasets/cryptonite_candidates/030000.jsonl' : 1000 in 38.15sec\n",
      "Wrote './datasets/cryptonite_candidates/031000.jsonl' : 1000 in 34.74sec\n",
      "Wrote './datasets/cryptonite_candidates/032000.jsonl' : 1000 in 35.93sec\n",
      "Wrote './datasets/cryptonite_candidates/033000.jsonl' : 1000 in 36.19sec\n",
      "Wrote './datasets/cryptonite_candidates/034000.jsonl' : 1000 in 40.71sec\n",
      "Wrote './datasets/cryptonite_candidates/035000.jsonl' : 1000 in 38.70sec\n",
      "Wrote './datasets/cryptonite_candidates/036000.jsonl' : 1000 in 35.21sec\n",
      "Wrote './datasets/cryptonite_candidates/037000.jsonl' : 1000 in 34.18sec\n",
      "Wrote './datasets/cryptonite_candidates/038000.jsonl' : 1000 in 34.45sec\n",
      "Wrote './datasets/cryptonite_candidates/039000.jsonl' : 1000 in 34.93sec\n",
      "Wrote './datasets/cryptonite_candidates/040000.jsonl' : 1000 in 34.86sec\n",
      "Wrote './datasets/cryptonite_candidates/041000.jsonl' : 1000 in 35.79sec\n",
      "Wrote './datasets/cryptonite_candidates/042000.jsonl' : 1000 in 34.45sec\n",
      "Wrote './datasets/cryptonite_candidates/043000.jsonl' : 1000 in 34.98sec\n",
      "Wrote './datasets/cryptonite_candidates/044000.jsonl' : 1000 in 36.07sec\n",
      "Wrote './datasets/cryptonite_candidates/045000.jsonl' : 1000 in 34.20sec\n",
      "Wrote './datasets/cryptonite_candidates/046000.jsonl' : 1000 in 34.80sec\n",
      "Wrote './datasets/cryptonite_candidates/047000.jsonl' : 1000 in 35.62sec\n",
      "Wrote './datasets/cryptonite_candidates/048000.jsonl' : 1000 in 34.51sec\n",
      "Wrote './datasets/cryptonite_candidates/049000.jsonl' : 1000 in 37.16sec\n",
      "Wrote './datasets/cryptonite_candidates/050000.jsonl' : 1000 in 36.18sec\n",
      "Wrote './datasets/cryptonite_candidates/051000.jsonl' : 1000 in 35.73sec\n",
      "Wrote './datasets/cryptonite_candidates/052000.jsonl' : 1000 in 36.21sec\n",
      "Wrote './datasets/cryptonite_candidates/053000.jsonl' : 1000 in 35.13sec\n",
      "Wrote './datasets/cryptonite_candidates/054000.jsonl' : 1000 in 36.44sec\n",
      "Wrote './datasets/cryptonite_candidates/055000.jsonl' : 1000 in 35.52sec\n",
      "Wrote './datasets/cryptonite_candidates/056000.jsonl' : 1000 in 35.45sec\n",
      "Wrote './datasets/cryptonite_candidates/057000.jsonl' : 1000 in 37.04sec\n",
      "Wrote './datasets/cryptonite_candidates/058000.jsonl' : 1000 in 35.44sec\n",
      "Wrote './datasets/cryptonite_candidates/059000.jsonl' : 1000 in 37.51sec\n",
      "Wrote './datasets/cryptonite_candidates/060000.jsonl' : 1000 in 37.03sec\n",
      "Wrote './datasets/cryptonite_candidates/061000.jsonl' : 1000 in 36.06sec\n",
      "Wrote './datasets/cryptonite_candidates/062000.jsonl' : 1000 in 34.84sec\n",
      "Wrote './datasets/cryptonite_candidates/063000.jsonl' : 1000 in 34.64sec\n",
      "Wrote './datasets/cryptonite_candidates/064000.jsonl' : 1000 in 35.30sec\n",
      "Wrote './datasets/cryptonite_candidates/065000.jsonl' : 1000 in 35.99sec\n",
      "Wrote './datasets/cryptonite_candidates/066000.jsonl' : 1000 in 36.00sec\n",
      "Wrote './datasets/cryptonite_candidates/067000.jsonl' : 1000 in 35.34sec\n",
      "Wrote './datasets/cryptonite_candidates/068000.jsonl' : 1000 in 36.73sec\n",
      "Wrote './datasets/cryptonite_candidates/069000.jsonl' : 1000 in 36.18sec\n",
      "Wrote './datasets/cryptonite_candidates/070000.jsonl' : 1000 in 37.00sec\n",
      "Wrote './datasets/cryptonite_candidates/071000.jsonl' : 1000 in 36.06sec\n",
      "Wrote './datasets/cryptonite_candidates/072000.jsonl' : 1000 in 35.09sec\n",
      "Wrote './datasets/cryptonite_candidates/073000.jsonl' : 1000 in 36.37sec\n",
      "Wrote './datasets/cryptonite_candidates/074000.jsonl' : 1000 in 35.13sec\n",
      "Wrote './datasets/cryptonite_candidates/075000.jsonl' : 1000 in 35.63sec\n",
      "Wrote './datasets/cryptonite_candidates/076000.jsonl' : 1000 in 36.54sec\n",
      "Wrote './datasets/cryptonite_candidates/077000.jsonl' : 1000 in 34.59sec\n",
      "Wrote './datasets/cryptonite_candidates/078000.jsonl' : 1000 in 36.18sec\n",
      "Wrote './datasets/cryptonite_candidates/079000.jsonl' : 1000 in 35.01sec\n",
      "Wrote './datasets/cryptonite_candidates/080000.jsonl' : 1000 in 34.92sec\n",
      "Wrote './datasets/cryptonite_candidates/081000.jsonl' : 1000 in 34.46sec\n",
      "Wrote './datasets/cryptonite_candidates/082000.jsonl' : 1000 in 35.26sec\n",
      "Wrote './datasets/cryptonite_candidates/083000.jsonl' : 1000 in 33.88sec\n",
      "Wrote './datasets/cryptonite_candidates/084000.jsonl' : 1000 in 37.03sec\n",
      "Wrote './datasets/cryptonite_candidates/085000.jsonl' : 1000 in 34.39sec\n",
      "Wrote './datasets/cryptonite_candidates/086000.jsonl' : 1000 in 35.42sec\n",
      "Wrote './datasets/cryptonite_candidates/087000.jsonl' : 1000 in 36.12sec\n",
      "Wrote './datasets/cryptonite_candidates/088000.jsonl' : 1000 in 35.87sec\n",
      "Wrote './datasets/cryptonite_candidates/089000.jsonl' : 1000 in 35.59sec\n",
      "Wrote './datasets/cryptonite_candidates/090000.jsonl' : 1000 in 36.35sec\n",
      "Wrote './datasets/cryptonite_candidates/091000.jsonl' : 1000 in 36.16sec\n",
      "Wrote './datasets/cryptonite_candidates/092000.jsonl' : 1000 in 35.04sec\n",
      "Wrote './datasets/cryptonite_candidates/093000.jsonl' : 1000 in 34.93sec\n",
      "Wrote './datasets/cryptonite_candidates/094000.jsonl' : 1000 in 34.17sec\n",
      "Wrote './datasets/cryptonite_candidates/095000.jsonl' : 1000 in 34.27sec\n",
      "Wrote './datasets/cryptonite_candidates/096000.jsonl' : 1000 in 35.22sec\n",
      "Wrote './datasets/cryptonite_candidates/097000.jsonl' : 1000 in 35.22sec\n",
      "Wrote './datasets/cryptonite_candidates/098000.jsonl' : 1000 in 34.70sec\n",
      "Wrote './datasets/cryptonite_candidates/099000.jsonl' : 1000 in 37.66sec\n",
      "Wrote './datasets/cryptonite_candidates/100000.jsonl' : 1000 in 35.96sec\n",
      "Wrote './datasets/cryptonite_candidates/101000.jsonl' : 1000 in 36.32sec\n",
      "Wrote './datasets/cryptonite_candidates/102000.jsonl' : 1000 in 35.18sec\n",
      "Wrote './datasets/cryptonite_candidates/103000.jsonl' : 1000 in 37.27sec\n",
      "Wrote './datasets/cryptonite_candidates/104000.jsonl' : 1000 in 39.52sec\n",
      "Wrote './datasets/cryptonite_candidates/105000.jsonl' : 1000 in 35.62sec\n",
      "Wrote './datasets/cryptonite_candidates/106000.jsonl' : 1000 in 36.44sec\n",
      "Wrote './datasets/cryptonite_candidates/107000.jsonl' : 1000 in 35.63sec\n",
      "Wrote './datasets/cryptonite_candidates/108000.jsonl' : 1000 in 36.52sec\n",
      "Wrote './datasets/cryptonite_candidates/109000.jsonl' : 1000 in 35.78sec\n",
      "Wrote './datasets/cryptonite_candidates/110000.jsonl' : 1000 in 34.38sec\n",
      "Wrote './datasets/cryptonite_candidates/111000.jsonl' : 1000 in 35.22sec\n",
      "Wrote './datasets/cryptonite_candidates/112000.jsonl' : 1000 in 35.73sec\n",
      "Wrote './datasets/cryptonite_candidates/113000.jsonl' : 1000 in 34.32sec\n",
      "Wrote './datasets/cryptonite_candidates/114000.jsonl' : 1000 in 34.33sec\n",
      "Wrote './datasets/cryptonite_candidates/115000.jsonl' : 1000 in 35.77sec\n",
      "Wrote './datasets/cryptonite_candidates/116000.jsonl' : 1000 in 33.28sec\n",
      "Wrote './datasets/cryptonite_candidates/117000.jsonl' : 1000 in 35.18sec\n",
      "Wrote './datasets/cryptonite_candidates/118000.jsonl' : 1000 in 35.63sec\n",
      "Wrote './datasets/cryptonite_candidates/119000.jsonl' : 1000 in 36.11sec\n",
      "Wrote './datasets/cryptonite_candidates/120000.jsonl' : 1000 in 37.18sec\n",
      "Wrote './datasets/cryptonite_candidates/121000.jsonl' : 1000 in 36.25sec\n",
      "Wrote './datasets/cryptonite_candidates/122000.jsonl' : 1000 in 36.40sec\n",
      "Wrote './datasets/cryptonite_candidates/123000.jsonl' : 1000 in 35.27sec\n",
      "Wrote './datasets/cryptonite_candidates/124000.jsonl' : 1000 in 36.18sec\n",
      "Wrote './datasets/cryptonite_candidates/125000.jsonl' : 1000 in 36.18sec\n",
      "Wrote './datasets/cryptonite_candidates/126000.jsonl' : 1000 in 34.67sec\n",
      "Wrote './datasets/cryptonite_candidates/127000.jsonl' : 1000 in 34.51sec\n",
      "Wrote './datasets/cryptonite_candidates/128000.jsonl' : 1000 in 36.49sec\n",
      "Wrote './datasets/cryptonite_candidates/129000.jsonl' : 1000 in 34.48sec\n",
      "Wrote './datasets/cryptonite_candidates/130000.jsonl' : 1000 in 35.22sec\n",
      "Wrote './datasets/cryptonite_candidates/131000.jsonl' : 1000 in 34.98sec\n",
      "Wrote './datasets/cryptonite_candidates/132000.jsonl' : 1000 in 37.47sec\n",
      "Wrote './datasets/cryptonite_candidates/133000.jsonl' : 1000 in 35.11sec\n",
      "Wrote './datasets/cryptonite_candidates/134000.jsonl' : 1000 in 35.79sec\n",
      "Wrote './datasets/cryptonite_candidates/135000.jsonl' : 1000 in 34.91sec\n",
      "Wrote './datasets/cryptonite_candidates/136000.jsonl' : 1000 in 34.83sec\n",
      "Wrote './datasets/cryptonite_candidates/137000.jsonl' : 1000 in 36.10sec\n",
      "Wrote './datasets/cryptonite_candidates/138000.jsonl' : 1000 in 37.29sec\n",
      "Wrote './datasets/cryptonite_candidates/139000.jsonl' : 1000 in 35.63sec\n",
      "Wrote './datasets/cryptonite_candidates/140000.jsonl' : 1000 in 35.52sec\n",
      "Wrote './datasets/cryptonite_candidates/141000.jsonl' : 1000 in 38.35sec\n",
      "Wrote './datasets/cryptonite_candidates/142000.jsonl' : 1000 in 36.20sec\n",
      "Wrote './datasets/cryptonite_candidates/143000.jsonl' : 1000 in 34.69sec\n",
      "Wrote './datasets/cryptonite_candidates/144000.jsonl' : 1000 in 35.20sec\n",
      "Wrote './datasets/cryptonite_candidates/145000.jsonl' : 1000 in 35.62sec\n",
      "Wrote './datasets/cryptonite_candidates/146000.jsonl' : 1000 in 35.61sec\n",
      "Wrote './datasets/cryptonite_candidates/147000.jsonl' : 1000 in 34.09sec\n",
      "Wrote './datasets/cryptonite_candidates/148000.jsonl' : 1000 in 36.40sec\n",
      "Wrote './datasets/cryptonite_candidates/149000.jsonl' : 1000 in 35.66sec\n",
      "Wrote './datasets/cryptonite_candidates/150000.jsonl' : 1000 in 36.55sec\n",
      "Wrote './datasets/cryptonite_candidates/151000.jsonl' : 1000 in 35.70sec\n",
      "Wrote './datasets/cryptonite_candidates/152000.jsonl' : 1000 in 36.11sec\n",
      "Wrote './datasets/cryptonite_candidates/153000.jsonl' : 1000 in 34.74sec\n",
      "Wrote './datasets/cryptonite_candidates/154000.jsonl' : 1000 in 35.80sec\n",
      "Wrote './datasets/cryptonite_candidates/155000.jsonl' : 1000 in 35.39sec\n",
      "Wrote './datasets/cryptonite_candidates/156000.jsonl' : 1000 in 36.27sec\n",
      "Wrote './datasets/cryptonite_candidates/157000.jsonl' : 1000 in 36.07sec\n",
      "Wrote './datasets/cryptonite_candidates/158000.jsonl' : 1000 in 35.06sec\n",
      "Wrote './datasets/cryptonite_candidates/159000.jsonl' : 1000 in 36.22sec\n",
      "Wrote './datasets/cryptonite_candidates/160000.jsonl' : 1000 in 34.08sec\n",
      "Wrote './datasets/cryptonite_candidates/161000.jsonl' : 1000 in 36.48sec\n",
      "Wrote './datasets/cryptonite_candidates/162000.jsonl' : 1000 in 36.05sec\n",
      "Wrote './datasets/cryptonite_candidates/163000.jsonl' : 1000 in 35.69sec\n",
      "Wrote './datasets/cryptonite_candidates/164000.jsonl' : 1000 in 37.17sec\n",
      "Wrote './datasets/cryptonite_candidates/165000.jsonl' : 1000 in 35.23sec\n",
      "Wrote './datasets/cryptonite_candidates/166000.jsonl' : 1000 in 36.60sec\n",
      "Wrote './datasets/cryptonite_candidates/167000.jsonl' : 1000 in 34.43sec\n",
      "Wrote './datasets/cryptonite_candidates/168000.jsonl' : 1000 in 35.99sec\n",
      "Wrote './datasets/cryptonite_candidates/169000.jsonl' : 1000 in 36.01sec\n",
      "Wrote './datasets/cryptonite_candidates/170000.jsonl' : 1000 in 34.99sec\n",
      "Wrote './datasets/cryptonite_candidates/171000.jsonl' : 1000 in 36.44sec\n",
      "Wrote './datasets/cryptonite_candidates/172000.jsonl' : 1000 in 35.12sec\n",
      "Wrote './datasets/cryptonite_candidates/173000.jsonl' : 1000 in 35.89sec\n",
      "Wrote './datasets/cryptonite_candidates/174000.jsonl' : 1000 in 35.31sec\n",
      "Wrote './datasets/cryptonite_candidates/175000.jsonl' : 1000 in 34.65sec\n",
      "Wrote './datasets/cryptonite_candidates/176000.jsonl' : 1000 in 34.18sec\n",
      "Wrote './datasets/cryptonite_candidates/177000.jsonl' : 1000 in 34.74sec\n",
      "Wrote './datasets/cryptonite_candidates/178000.jsonl' : 1000 in 35.65sec\n",
      "Wrote './datasets/cryptonite_candidates/179000.jsonl' : 1000 in 35.13sec\n",
      "Wrote './datasets/cryptonite_candidates/180000.jsonl' : 1000 in 34.32sec\n",
      "Wrote './datasets/cryptonite_candidates/181000.jsonl' : 1000 in 34.22sec\n",
      "Wrote './datasets/cryptonite_candidates/182000.jsonl' : 1000 in 36.65sec\n",
      "Wrote './datasets/cryptonite_candidates/183000.jsonl' : 1000 in 34.66sec\n",
      "Wrote './datasets/cryptonite_candidates/184000.jsonl' : 1000 in 35.11sec\n",
      "Wrote './datasets/cryptonite_candidates/185000.jsonl' : 1000 in 35.20sec\n",
      "Wrote './datasets/cryptonite_candidates/186000.jsonl' : 1000 in 34.80sec\n",
      "Wrote './datasets/cryptonite_candidates/187000.jsonl' : 1000 in 34.21sec\n",
      "Wrote './datasets/cryptonite_candidates/188000.jsonl' : 1000 in 33.18sec\n",
      "Wrote './datasets/cryptonite_candidates/189000.jsonl' : 1000 in 33.86sec\n",
      "Wrote './datasets/cryptonite_candidates/190000.jsonl' : 1000 in 33.82sec\n",
      "Wrote './datasets/cryptonite_candidates/191000.jsonl' : 1000 in 33.78sec\n",
      "Wrote './datasets/cryptonite_candidates/192000.jsonl' : 1000 in 34.47sec\n",
      "Wrote './datasets/cryptonite_candidates/193000.jsonl' : 1000 in 34.47sec\n",
      "Wrote './datasets/cryptonite_candidates/194000.jsonl' : 1000 in 35.78sec\n",
      "Wrote './datasets/cryptonite_candidates/195000.jsonl' : 1000 in 35.32sec\n",
      "Wrote './datasets/cryptonite_candidates/196000.jsonl' : 1000 in 35.79sec\n",
      "Wrote './datasets/cryptonite_candidates/197000.jsonl' : 1000 in 35.17sec\n",
      "Wrote './datasets/cryptonite_candidates/198000.jsonl' : 1000 in 36.48sec\n",
      "Wrote './datasets/cryptonite_candidates/199000.jsonl' : 1000 in 36.20sec\n"
     ]
    }
   ],
   "source": [
    "# Process cryptonite.train in batches of 100 ...\n",
    "data_dir = './datasets/cryptonite_candidates'\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "max_data_train=min(200_000, len(data_train))\n",
    "#max_data_train=min(321, len(data_train))\n",
    "for base in range(0, max_data_train, 1000):\n",
    "  arr = [ data_train[shuffled_idx_train[idx]] for idx in range(base, min(base+1000, max_data_train)) ]\n",
    "  fname = f\"{data_dir}/{base:06d}.jsonl\"\n",
    "  if not os.path.isfile(fname):\n",
    "    t0=time.time()\n",
    "    with open(fname, 'w') as fjson:\n",
    "      random.seed(42+base, version=2)\n",
    "      arr = add_embedding_nearest_from_definition_candidates_for_dataset(arr)\n",
    "      for a in arr:\n",
    "        json.dump(a, fjson)\n",
    "        fjson.write('\\n')\n",
    "    elapsed=(time.time()-t0)\n",
    "    print(f\"Wrote '{fname}' : {len(arr)} in {elapsed:.2f}sec\")  #: {base:06d}\n",
    "\"DONE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "ddf346df-6bed-4ef6-a70e-65b8f033ef3a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--. 1 69585809 May 22 01:05 ./datasets/cryptonite_candidates_2024-05-21_train.jsonl\n"
     ]
    }
   ],
   "source": [
    "## Confirm that this shows the files in numerical order:\n",
    "# for a in ./datasets/cryptonite_candidates/*.jsonl ; do echo $a ; done\n",
    "## Concatenate these training files together\n",
    "# for a in ./datasets/cryptonite_candidates/*.jsonl ; do cat $a >> ./datasets/cryptonite_candidates_2024-05-21_train.jsonl ; done\n",
    "! ls -l -Gg ./datasets/*.jsonl  # No username for anonymity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b388e82-df2b-4e6a-9404-c6f512fade83",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "os.makedirs('./datasets', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df6d5bee-bf4c-43ec-9956-27568d65477a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc739808dd024490a0e46331e2de759d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/200 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "64985844"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "arr=[]\n",
    "with open('./datasets/cryptonite_candidates_2024-05-21_train.jsonl', 'r') as f:\n",
    "  for idx, line in enumerate(f.readlines()):\n",
    "    data = json.loads(line)\n",
    "    data['number']=str(data['number'])\n",
    "    arr.append(data)\n",
    "    #if idx % 1000==0:\n",
    "    #  print(f\"{idx} : OK\")\n",
    "\n",
    "Dataset.from_pandas(pd.DataFrame(arr)).to_json(f'./datasets/cryptonite_candidates_2024-05-21_train.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d04edd3-4397-4246-a8d1-55863fdc0c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! cd datasets & zip ./datasets/cryptonite_candidates_2024-05-21_train.zip ./datasets/cryptonite_candidates_2024-05-21_train.json\n",
    "! ls -l -Gg ./datasets/*.zip  # No username for anonymity"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "cache-notebooks//ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
